# üß† AI Study Agent - RAG-Powered Learning Assistant

[![TypeScript](https://img.shields.io/badge/TypeScript-007ACC?style=flat&logo=typescript&logoColor=white)](https://www.typescriptlang.org/)
[![Electron](https://img.shields.io/badge/Electron-47848F?style=flat&logo=electron&logoColor=white)](https://www.electronjs.org/)
[![NVIDIA](https://img.shields.io/badge/NVIDIA-76B900?style=flat&logo=nvidia&logoColor=white)](https://build.nvidia.com/)
[![LangChain](https://img.shields.io/badge/LangChain-121212?style=flat)](https://js.langchain.com/)
[![ChromaDB](https://img.shields.io/badge/ChromaDB-FF6B6B?style=flat)](https://www.trychroma.com/)

An intelligent desktop study assistant powered by **NVIDIA NIM models**, **LangChain**, and **ChromaDB**. Uses Retrieval-Augmented Generation (RAG) to provide accurate, context-aware answers from your study materials.

## ‚ú® Features

- ü§ñ **Advanced AI Models**: NVIDIA's latest embedding (nv-embedqa-e5-v5) and chat models (Llama 3.1 70B)
- üìö **RAG Pipeline**: Retrieve relevant context from your documents before answering
- üóÑÔ∏è **Persistent Storage**: ChromaDB vector database for efficient semantic search
- üìù **Multi-Format Support**: PDF, Markdown, text files, and code files
- üéØ **Source Citations**: Automatic citation of sources in responses
- üí¨ **Conversational Memory**: Context-aware multi-turn conversations
- üîß **MCP Integration**: Extensible tool system via Model Context Protocol
- üé® **Modern UI**: React + Tailwind CSS with Electron

## üöÄ Quick Start

### Prerequisites

- Node.js 18+
- Docker (for ChromaDB)
- NVIDIA API Key ([Get one free](https://build.nvidia.com/))

### Installation

1. **Clone and install**

   ```bash
   git clone <repo-url>
   cd study-agent-RAG
   npm install
   ```

2. **Setup environment**

   ```bash
   cp .env.example .env
   # Edit .env and add your NVIDIA_API_KEY
   ```

3. **Start ChromaDB**

   ```bash
   docker run -p 8000:8000 chromadb/chroma
   ```

4. **Build and run**

   ```bash
   npm run build:mcp
   npm start
   ```

**Quick verification**: Run `.\verify-setup.ps1` to check all prerequisites.

## üìñ Documentation

- **[Complete Setup Guide](SETUP_GUIDE.md)** - Detailed installation and configuration
- **[Implementation Summary](IMPLEMENTATION_SUMMARY.md)** - Technical details and architecture
- **[Component Guide](COMPONENT_USAGE_GUIDE.md)** - UI components reference

## üß™ Testing

```bash
# Test NVIDIA API integration
npm run test:nvidia

# Test ChromaDB and RAG pipeline
npm run test:chromadb

# Test full agent end-to-end
npm run test:agent

# Run all tests
npm run test:all
```

## üéØ Technology Stack

### AI & ML

- **NVIDIA NIM**: Latest embedding and chat models
- **LangChain**: AI application framework
- **LangGraph**: State machine orchestration
- **ChromaDB**: Vector database for embeddings

### Application

- **Electron**: Cross-platform desktop app
- **React**: UI framework
- **TypeScript**: Type-safe development
- **Tailwind CSS**: Styling

## How the app is organized

Top-level files of interest

- forge.config.ts: Electron Forge configuration
- webpack.*.config.ts: Webpack config for main, renderer, rules, and plugins
- tsconfig.json: TypeScript configuration (strict mode)
- package.json: Scripts and dependencies

Source layout (selected)

- src/
  - index.ts: Electron main entry (BrowserWindow lifecycle, devtools on in development)
  - preload.ts: Safe API surface for renderer via contextBridge (IPC boundary)
  - renderer.ts, index.html, globals.css: Renderer bootstrap and global styles
  - App.tsx: Root render composition for the UI
  - client/
    - index.ts: Client entry for MCP-related exports
    - MCPClientManager.ts: Multi-server orchestration (connect, list tools, execute)
    - MCPSession.ts: A per-server session abstraction (capabilities, tool calls)
    - ConfigManager.ts: Config handling and persistence helpers
    - logger.ts: Centralized logging
    - types.ts: Shared types for client, transports, tools
  - transport/
    - StdioTransport.ts: STDIO transport abstraction for local MCP servers
  - components/
    - layout/ (MainLayout, Sidebar, TopBar, ContentContainer)
    - ui/ (Button, Card, Input, TextArea, LoadingSpinner, Badge, IconButton, MessageBubble, QuickActionCard)
  - views/
    - Chat.tsx: Chat view (agent interaction shell)
    - ServerManager.tsx: Manage MCP server connections and tool discovery
  - lib/
    - utils.ts: Utilities shared across UI and client

## Architecture overview

### System architecture (high-level)

```mermaid
flowchart LR
  subgraph Electron
    A[Main Process] -->|IPC| B[Preload]
    B -->|contextBridge| C[Renderer]
  end

  subgraph Client
    M[MCPClientManager] --> S2[MCPSession 1]
    M --> S1[MCPSession 2..N]
    S1 --> T1[Transport: STDIO or HTTP/SSE]
    S2 --> T2[Transport: STDIO]
  end

  C -->|UI actions| M
  T1 <-->|JSON-RPC| SV1[(MCP Server 1)]
  T2 <-->|JSON-RPC| SV2[(MCP Server 2)]
```

Process model

- Main process (Node.js): window lifecycle, future MCP session orchestration, logging, secured IPC
- Preload script: contextBridge to expose safe, typed APIs to the renderer
- Renderer process (Chromium): UI (chat, tool explorer, server manager), interaction with the preload API

Core layers and responsibilities

- Transport layer: abstracts how MCP messages flow (STDIO for local servers today; HTTP/SSE can be added)
- Session layer: manages one MCP server connection, negotiates capabilities (tools/resources/prompts/logging), lists tools, and executes tool calls
- Manager layer: multiplexes multiple sessions, aggregates tools across servers, and manages lifecycles
- UI layer: user workflows (chat, tool browsing, server lifecycle), results and errors surfaced clearly for learning feedback

Security model

- Context isolation enforced: Node.js APIs are not available in the renderer
- All privileged operations flow via preload and validated IPC calls
- Input validation and schema checking for tool execution is expected at the boundary (e.g., Zod)

### MCPSession lifecycle (states)

```mermaid
stateDiagram-v2
  [*] --> Disconnected
  Disconnected --> Connecting
  Connecting --> Initialized: capabilities negotiated
  Initialized --> Running: tools discovered
  Running --> Error: transport failure
  Error --> Reconnecting
  Reconnecting --> Running
  Running --> Disconnected: user disconnects
```

## How it works at runtime

- Startup: main creates a BrowserWindow, enables devtools in development, and loads the renderer entry
- Preload: exposes a minimal MCP API to the renderer, such as connecting to a server, listing tools, and executing tools
- Connection model: the manager creates one MCPSession per server; each session negotiates capabilities and supports tool discovery and execution
- UI: the Server Manager view handles connections and discovery; the Chat view is the space for agent interactions, streaming results, and study workflow orchestration

## Model Context Protocol (MCP) in this app

MCP is an open protocol that standardizes how clients and servers exchange tools, resources, prompts, logging, and sampling over JSON-RPC. The protocol is transport-agnostic and supports multiple transports (e.g., STDIO for local process servers and HTTP/SSE for remote servers). The client discovers server capabilities and reacts accordingly.

In practice

- Capabilities: a server may declare tools, prompts, resources, and logging; the client adapts the UI and API surface to what‚Äôs present
- Tool discovery: enumerate server tools with names, descriptions, and input schemas for safe calling
- Tool execution: validate inputs against schemas, provide parameters, receive structured results, and surface errors usefully
- Multi-server orchestration: maintain multiple concurrent sessions; ensure each message is routed to the correct session/transport; aggregate tools in a unified registry
- Transports: use STDIO for local processes; extend to HTTP/SSE for remote servers and streaming

What to expect from servers

- Tools: invoke actions (e.g., ‚Äúcreate_form‚Äù, ‚Äúsummarize_pdf‚Äù, ‚Äúgenerate_flashcards‚Äù)
- Prompts: predefined templates for consistent interactions
- Resources: named, fetchable pieces of context
- Logging: server-side logs delivered to the client for observability

References

- Model Context Protocol specification: capabilities (tools/prompts/resources/logging), streamable HTTP transport (including SSE) and multi-connection handling are covered in the public spec

### MCP tool execution sequence

```mermaid
sequenceDiagram
  participant UI
  participant Agent
  participant Manager as MCPClientManager
  participant Session as MCPSession
  participant Server as MCP Server

  UI->>Agent: User prompt
  Agent->>Manager: listTools(serverId)
  Manager->>Session: list_tools
  Session->>Server: capabilities/tools request
  Server-->>Session: tools metadata
  Session-->>Manager: tools
  Agent->>Manager: executeTool(serverId, toolName, params)
  Manager->>Session: call_tool
  Session->>Server: JSON-RPC request
  Server-->>Session: structured result
  Session-->>Manager: result
  Manager-->>Agent: result
  Agent-->>UI: answer + explanation
```

## Agent implementations you can adopt (no code included)

You can power the app‚Äôs agent behaviors with one of three production-ready paths. Each integrates cleanly with the MCP client and UI. Choose based on your infra, ecosystem preference, and deployment constraints.

### Option A ‚Äî LangChain-based RAG (JavaScript/TypeScript)

Concept

- Use LangChain‚Äôs retrieval and agent primitives in TypeScript to implement Retrieval-Augmented Generation (RAG) and tool-using agents
- Combine chunking, embedding, vector search, reranking, and response synthesis
- Add tools for file loading, PDF parsing, web fetches, or domain-specific actions; expose callable tools from MCP servers to the agent

Typical flow

- Ingestion: parse PDFs and notes; chunk with a recursive splitter; generate embeddings; index into a vector store
- Retrieval: create a retriever with a suitable search strategy (e.g., similarity, MMR) and optional reranker for quality
- Augmentation: construct compact, well-structured context windows tailored to questions
- Agent loop: enable tool use for browsing documents or calling MCP tools (e.g., quiz generation). Use typed schemas and guardrails for tool I/O
- Evaluation: measure groundedness, faithfulness, and answer accuracy using offline datasets and spot checks; iterate on chunk size, overlap, retriever parameters, and reranker choice

When to pick this

- You prefer TypeScript end-to-end and want a vibrant OSS ecosystem
- You need full control over your RAG pipeline and vector store
- You plan to integrate multiple MCP servers as tool sources for the agent

What to prepare

- A vector database or embed + local store strategy
- A reranker if you need higher answer quality on longer documents
- API keys for your chosen model provider

### Option B ‚Äî NVIDIA path: NeMo Agent Toolkit and NIMs

Concept

- Use NVIDIA‚Äôs NeMo Agent Toolkit to build and observe tool-using agents with first-class evaluation and profiling support
- Integrate RAG with NVIDIA NIM microservices when you need GPU-accelerated inference or enterprise observability

Typical flow

- Agent wiring: define tools and workflows; integrate with your data sources and business logic
- Observability: enable tracing with supported backends to understand tool decisions, latency, and bottlenecks
- Evaluation: run structured evaluation on datasets (e.g., RAG accuracy, groundedness, relevance, and trajectory accuracy) to benchmark changes
- Scaling: deploy NIM-backed endpoints for model and reranker services, and keep agent logic portable

When to pick this

- You‚Äôre standardizing on NVIDIA stacks or need GPU acceleration and enterprise observability
- You want built-in evaluation, profiling, and a structured agent development lifecycle

What to prepare

- Access to NVIDIA services or on-prem GPUs
- Evaluation datasets (question/answer pairs and acceptance criteria)
- Credentials for model endpoints or NIM instances

### Option C ‚Äî Google path: Vertex AI Agent Builder (Agent Engine, Memory Bank) and RAG API

Concept

- Use Vertex AI Agent Builder to create tool-using agents, manage long-term memory with Memory Bank, and ground answers via RAG API
- Combine tools/actions, memory, and knowledge bases to deliver reliable study assistants

Typical flow

- Tools/actions: define agent-executable actions (e.g., import study material, create quizzes via a Google Forms MCP server)
- Memory Bank: capture durable, scoped ‚Äúfacts‚Äù about users/sessions to personalize study guidance
- Knowledge and grounding: connect document stores or enterprise search; use Vertex AI RAG API for retrieval and grounding
- Governance: apply enterprise security, quotas, and monitoring via Google Cloud

When to pick this

- You operate on Google Cloud and want managed agents, grounding, and memory primitives
- You need native integration with Vertex AI models (Gemini) and connectors

What to prepare

- A Google Cloud project with Vertex AI enabled
- Agent definitions, memory scopes, and access to a knowledge source or RAG API
- Credentials and IAM policies configured for your environment

## How MCP, agents, and UI fit together

- Server connections: the app establishes sessions to one or more MCP servers (e.g., a PDF tools server, a Google Forms server, and a web search server)
- Discovery: sessions enumerate tools and capabilities; the UI shows a consolidated tool catalog
- Agent backbone: your chosen agent stack (LangChain, NeMo, or Vertex AI) is responsible for selecting and sequencing tools; the MCP client executes tool calls safely and returns structured results
- Results rendering: responses, partial updates, and tool outputs appear in the Chat view; errors are captured and explained for learning feedback

### Layers and options

```mermaid
flowchart LR
  subgraph UI_Layer[UI Layer]
    Chat[Chat View]
    ServerMgr[Server Manager]
  end

  subgraph Agent_Layer[Agent Layer]
    AgentA[LangChain Agent (Option A)]
    AgentB[NeMo Agent Toolkit (Option B)]
    AgentC[Vertex AI Agent Builder (Option C)]
  end

  subgraph MCP_Layer[MCP Layer]
    Manager2[MCPClientManager]
    Session2[MCPSession x N]
  end

  subgraph Transport[Transport]
    STDIO[STDIO]
    HTTP[HTTP/SSE]
  end

  subgraph Servers[MCP Servers]
    PDF[(PDF Tools)]
    Forms[(Google Forms)]
    Search[(Web Search)]
  end

  Chat --> AgentA
  Chat --> AgentB
  Chat --> AgentC
  ServerMgr --> Manager2
  AgentA --> Manager2
  AgentB --> Manager2
  AgentC --> Manager2
  Manager2 --> Session2
  Session2 --> STDIO
  Session2 --> HTTP
  STDIO --> PDF
  STDIO --> Forms
  STDIO --> Search
  HTTP --> PDF
  HTTP --> Forms
  HTTP --> Search
```

## Typical study workflows (composed via tools)

- Summarize PDFs: ingest one or more PDFs, chunk, embed, and retrieve the most relevant sections; produce concise summaries per goal
- Generate flashcards: transform retrieved content into high-quality Q/A flashcards with difficulty tags and spacing suggestions
- Quiz creation: call a quiz-generation MCP tool (e.g., Google Forms) to produce a shareable quiz link
- Mentor loop: use memory to track learner progress, reinforce weak areas, and adapt difficulty over time

### Study workflow (RAG pipeline)

```mermaid
flowchart TD
  U[User PDFs/Notes] --> I[Ingestion & Chunking]
  I --> E[Embeddings]
  E --> VS[(Vector Store)]
  Q[Question] --> R[Retriever]
  VS --> R
  R --> A[Augmented Prompt]
  A --> LLM[LLM]
  LLM --> Out[Summary / Flashcards / Quiz Items]
  Out -->|MCP Tool| GF[Google Forms (MCP)]
  Out --> UI[Chat + Review]
```

## Configuration and environment

- Configuration management is centralized in client utilities and the MCP manager
- Provide model and provider credentials strictly via environment configuration or OS keychain, not hard-coded into the renderer
- For MCP servers, define connection parameters (e.g., executable path for STDIO or endpoint for HTTP/SSE) and expected capabilities
- Validate all IPC inputs (e.g., Zod schemas) and sanitize any user-provided paths or network targets

## Extending transports and sessions

- Add HTTP/SSE transport for remote MCP servers if you plan to host them behind secure endpoints
- Support multiple concurrent streams responsibly (the MCP spec allows simultaneous connections; ensure messages are not duplicated across streams)
- Apply origin validation and authentication for any HTTP-based transport in untrusted networks

## UI overview

- Chat view: multi-turn interactions, tool results, and explanations; designed to encourage learning, not just answers
- Server Manager: add/remove MCP servers, inspect capabilities, and test tool calls
- Tool Explorer (future): browse, filter, and learn about available tools and their schemas

## Quality, testing, and reliability

- Type safety: TypeScript across main, preload, and renderer; avoid any unsafe escape hatches in renderer
- Error handling: surface tool execution errors clearly; prefer typed result wrappers with clear success/failure states and messages
- Evaluation: for RAG or agent logic, use offline datasets and structured evaluators (e.g., groundedness, relevance, and accuracy) before rolling changes into study sessions
- Observability: enable tracing for tool calls, agent decisions, and latency to drive continuous improvement

## Production considerations

- Security: principle of least privilege; context isolation; strict input validation; avoid enabling Node integration in renderer
- Data governance: treat sensitive PDFs and quiz content according to your organization‚Äôs policies; encrypt at rest and in transit if storing locally
- Performance: monitor chunk sizes, embedding throughput, and retriever latencies; add reranking where it improves answer quality
- Upgradability: keep the MCP client decoupled from your agent implementation to switch stacks with minimal effort

## Roadmap

- Add HTTP/SSE transport implementation alongside STDIO
- Implement a Tool Explorer UI with schema-first inspection and sample calls
- Provide optional built-in vector store and reranker integration for a ready-to-run RAG pipeline
- Add first-party connectors for common study sources (cloud drives, LMS systems)
- Ship evaluation harness references for each agent path (LangChain, NVIDIA, Google)

## Glossary

- MCP (Model Context Protocol): a protocol for standardizing client/server interactions around tools, prompts, resources, logging, and sampling via JSON-RPC over pluggable transports
- Tool: a callable operation exposed by an MCP server with a name, description, and input schema
- RAG (Retrieval-Augmented Generation): a pattern that retrieves relevant context from a knowledge base and augments the model‚Äôs input to improve factuality and specificity
- Memory: durable user or session facts used by agents to personalize behavior over time (e.g., Google Vertex AI Memory Bank)

## References (overview)

- Model Context Protocol: specification, capabilities, and transports (including HTTP/SSE)
- LangChain (JavaScript/TypeScript): agents, tools, and retrieval patterns for RAG applications
- NVIDIA NeMo/Agent Toolkit: agent development, observability, evaluation, and NIM-backed deployment
- Google Vertex AI Agent Builder: tools/actions, Memory Bank, RAG API, and grounding on Google Cloud
